<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>X. Wei's Blog</title><link href="http://x-wei.github.com" rel="alternate"></link><link href="http://x-wei.github.com/feeds/python.atom.xml" rel="self"></link><id>http://x-wei.github.com</id><updated>2012-06-07T20:14:00+02:00</updated><entry><title>水源PPP板图片下载器</title><link href="http://x-wei.github.com/%E6%B0%B4%E6%BA%90PPP%E6%9D%BF%E5%9B%BE%E7%89%87%E4%B8%8B%E8%BD%BD%E5%99%A8.html" rel="alternate"></link><updated>2012-06-07T20:14:00+02:00</updated><author><name>X.Wei</name></author><id>http://x-wei.github.com/水源PPP板图片下载器.html</id><summary type="html">&lt;p&gt;这个其实是三月份的时候做的, 当时刚刚学会用urllib和正则表达式做一些爬虫, 于是结合人民群众的需要, 写了个小脚本(福利~) &lt;/p&gt;
&lt;p&gt;不过现在我还只是会照葫芦画瓢那样用urllib, 没什么长进...&lt;/p&gt;
&lt;p&gt;github地址: &lt;a href="https://github.com/X-Wei/yssy_ppp_pic_downloader"&gt;https://github.com/X-Wei/yssy_ppp_pic_downloader&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.&lt;/p&gt;
&lt;p&gt;功能就是下载水源ppperson板里帖子的图片, 并且每个帖子一个文件夹放好. 通过修改main函数可以选择下载最近一页的帖子还是下载全部帖子(或者最近几页的帖子)&lt;/p&gt;
&lt;p&gt;原理很简单, 分析网页的html代码, 用正则表达式找出图片的地址然后下载到本地. 当时我已经写了两三个简单的爬虫, 所以这个写得蛮快, 而且只用50行就搞定了...&lt;/p&gt;
&lt;p&gt;不会用多线程, 只能一张一张下载, 帖子数目实在太多了, 我让它跑了一晚上, 第二天跑完, 下载了8个G的图, 几千个文件夹(囧)......&lt;/p&gt;
&lt;p&gt;2.&lt;/p&gt;
&lt;p&gt;不过还是遇到了一些问题, 比较老的帖子会有些图片404, 这时或者这个帖子对应的文件夹为空, 或者里面的图片其实不是图片, 而是出错信息的html代码(虽然看后缀是个图片). 我需要把那些不是图片的文件删掉, 而且要删掉所有的空文件夹. &lt;/p&gt;
&lt;p&gt;删除不是图片的文件(其实应该是删除纯文本文件), 在水源发贴问, 用shell命令(perl)做到了(虽然不明白为什么这样写...):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;find yssy_ppp/ -type f | perl -ne 'chomp;unlink "$_" if -T $_'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;关于删除空目录, 发现&lt;code&gt;rmdir&lt;/code&gt;命令就已经可以了, 会删除空文件夹, 非空文件夹不会删除(虽然会显示警告).&lt;/p&gt;
&lt;p&gt;python里面调用shell命令只需要:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;os.system("shell_command")&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所以, 只需要在程序的最后加上两行:
    os.system('''find yssy_ppp/ -type f | perl -ne 'chomp;unlink "$&lt;em&gt;" if -T $&lt;/em&gt;' ''')
    os.system('rmdir yssy_ppp/*')&lt;/p&gt;
&lt;p&gt;虽然终端里运行时最后会因为那个&lt;code&gt;rmdir&lt;/code&gt;命令出一堆警告, 但是既然功能实现了就懒得改了...&lt;/p&gt;
&lt;p&gt;3.&lt;/p&gt;
&lt;p&gt;还写(改写)过一个人人相册下载的脚本, 不过需要改进, 不知毕业前能不能搞定......&lt;/p&gt;</summary><category term="git"></category><category term="python"></category><category term="shell"></category></entry><entry><title>github上两个比较有用的小项目</title><link href="http://x-wei.github.com/github%E4%B8%8A%E4%B8%A4%E4%B8%AA%E6%AF%94%E8%BE%83%E6%9C%89%E7%94%A8%E7%9A%84%E5%B0%8F%E9%A1%B9%E7%9B%AE.html" rel="alternate"></link><updated>2012-05-31T00:00:00+02:00</updated><author><name>X.Wei</name></author><id>http://x-wei.github.com/github上两个比较有用的小项目.html</id><summary type="html">&lt;p&gt;github上的好东西不少, 最近发现了两个比较有用的python程序, 这俩功能都是我比较想要的, 有需求就会有牛人去实现~&lt;/p&gt;
&lt;h1 id="1_+++++youku-lixian"&gt;1. 视频下载器youku-lixian&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://github.com/iambus/youku-lixian"&gt;https://github.com/iambus/youku-lixian&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可不止支持下载优酷的视频奥, 土豆, 奇艺, 新浪, 酷6...... 通吃~&lt;/p&gt;
&lt;p&gt;而且每个都只是一个小小的py文件, 直接就可以运行, 比起什么优酷客户端, 奇艺客户端小多了! 太赞了!~&lt;/p&gt;
&lt;h1 id="2_115++++++"&gt;2. 115网盘自动摇奖&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://gist.github.com/2698830"&gt;https://gist.github.com/2698830&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个功能我曾经想要实现, 但是关于网络通信方面知道的太少了, 搞了一通也没有成功. 现在有人把它共享出来, 代码居然还不到100行, 强大啊~&lt;/p&gt;</summary><category term="git"></category><category term="python"></category></entry></feed>